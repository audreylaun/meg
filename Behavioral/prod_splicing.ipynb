{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
   "id": "4e90a225-c9b5-4ffe-84ec-939cea79fec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pydub numpy scipy soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b7b0742-91ae-4050-8522-8f0a8fc31a44",
   "metadata": {},
   "outputs": [],
=======
   "id": "4e90a225-c9b5-4ffe-84ec-939cea79fec8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T16:49:58.279493Z",
     "start_time": "2025-09-24T16:49:58.275020Z"
    }
   },
   "source": [
    "# pip install pydub numpy scipy soundfile"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "9b7b0742-91ae-4050-8522-8f0a8fc31a44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T14:19:21.792076Z",
     "start_time": "2025-09-29T14:19:19.979952Z"
    }
   },
>>>>>>> 99371e3f79805ce2c9605203223f22b6524c6a64
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from scipy.io.wavfile import write\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat "
<<<<<<< HEAD
   ]
=======
   ],
   "outputs": [],
   "execution_count": 1
>>>>>>> 99371e3f79805ce2c9605203223f22b6524c6a64
  },
  {
   "cell_type": "markdown",
   "id": "3f7030ef-1509-4d8c-954a-765ac2d5275e",
   "metadata": {},
   "source": [
    "## Functions for detecting pulses and splicing the audio "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "id": "dec13add-e6b6-4ec9-b02b-cb031fc024fe",
   "metadata": {},
   "outputs": [],
=======
   "id": "dec13add-e6b6-4ec9-b02b-cb031fc024fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T14:19:21.801597Z",
     "start_time": "2025-09-29T14:19:21.798286Z"
    }
   },
>>>>>>> 99371e3f79805ce2c9605203223f22b6524c6a64
   "source": [
    "def detect_pulses(pulse_samples, sample_rate, amp_threshold=600000000, min_distance_ms=100):\n",
    "    ''' \n",
    "    pulse_samples = array of pulse channel wav (0th element of every array that audio_data contains)\n",
    "    sample_rate = sampling rate of audio recorder \n",
    "    amp_threshold = minimum value for a value to be considered a pulse \n",
    "    min_distance_ms = minimum length of a pulse \n",
    "\n",
    "    Uses the pulse channel amplitudes to detect all instances of a pulse \n",
    "\n",
    "    Returns the indexes of the peaks in the audio file \n",
    "    '''\n",
    "    min_distance = int((min_distance_ms / 1000) * sample_rate)\n",
    "    peaks, _ = signal.find_peaks(pulse_samples, height=amp_threshold, distance=min_distance)\n",
    "    return peaks\n",
    "\n",
    "def drop_until_length(arr, target_length):\n",
    "    '''\n",
    "    arr = input array\n",
    "    target_length = length of the array you would like \n",
    "\n",
    "    drops the first elements of an input array until it reaches the target length \n",
    "    '''\n",
    "    if len(arr) <= target_length:\n",
    "        return arr[:]  \n",
    "    else:\n",
    "        return arr[len(arr) - target_length:]\n",
    "            \n",
    "def slice_audio(audio_channel_0, peaks, sample_rate, output_dir):\n",
    "    '''\n",
    "    audio_channel_0 = array of audio recording wav (1st element of every array that audio_data contains)\n",
    "    peaks = the indexes of the peaks found in the audio file (from detect_pulses)\n",
    "    sample_rate = sampling rate of audio recorder\n",
    "    output_dir = output directory for the spliced files \n",
    "\n",
    "    Splices the voice recording into separate elements for every word produced, naming each file with the word that should have been said\n",
    "    '''\n",
    "    #Creates directory if one does not exist already \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    #Sets variables for the final file name, to be used after for loop\n",
    "    last_start=0\n",
    "    last_end = len(audio_channel_0)\n",
    "    last_index = 0\n",
    "\n",
    "    # Deals with situations where the recording started during the practice trials \n",
    "    if 150 < len(peaks)<154: \n",
    "        peaks = drop_until_length(peaks, 150)\n",
    "        names = no_practice\n",
    "    \n",
    "    # Sets the names of the files to include practice trials (if you started recording before practice trials)\n",
    "    elif len(peaks)==154:\n",
    "        names = with_practice\n",
    "   \n",
    "    # Sets the names of the files to not include practice trials (if you started recording after practice trials)\n",
    "    else: \n",
    "        names = no_practice\n",
    "\n",
    "    #Saves all but the last audio file, titling each file with the word that should have been uttered \n",
    "    for i in range(len(peaks) - 1): \n",
    "        start_index = peaks[i]\n",
    "        end_index = peaks[i + 1]\n",
    "\n",
    "        segment = audio_channel_0[start_index:end_index]\n",
    "        if i < 10: \n",
    "            title = '00' + str(i)+ names[i] + '.wav'\n",
    "        elif 10 <= i < 100: \n",
    "            title = '0' + str(i) + names[i] + '.wav' \n",
    "        else: \n",
    "            title = str(i)+ names[i] + '.wav'\n",
    "        write(os.path.join(output_dir, title), sample_rate, np.array(segment))\n",
    "        last_start = end_index\n",
    "        last_index = i+1\n",
    "       \n",
    "    #Saves the last audio file, titling the file with the word that should have been uttered \n",
    "    segment = audio_channel_0[last_start:last_end]\n",
    "    title = str(len(peaks)-1)+ names[len(names)-1] + '.wav'\n",
    "    write(os.path.join(output_dir, title), sample_rate, np.array(segment))\n",
    "\n",
    "    print(f\"Saved {len(peaks)} segments to {output_dir}\")\n"
<<<<<<< HEAD
   ]
=======
   ],
   "outputs": [],
   "execution_count": 2
>>>>>>> 99371e3f79805ce2c9605203223f22b6524c6a64
  },
  {
   "cell_type": "markdown",
   "id": "ff201531-ba12-4983-b444-43611a2e5de9",
   "metadata": {},
   "source": [
    "## Change file path, directory path, and word list for each subject\n",
    "\n",
    "No other cells need to be edited. "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 67,
   "id": "3f2edfed-a426-4661-b10e-97ea148d3c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"/Users/admin/Box Sync/Starling/MEG_data/R3289/R3289.WAV\"\n",
    "output_dir = \"/Users/admin/Box Sync/Starling/MEG_data/R3289/Recordings\" \n",
    "word_list = \"A2\""
   ]
=======
   "id": "3f2edfed-a426-4661-b10e-97ea148d3c3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T14:19:57.206440Z",
     "start_time": "2025-09-29T14:19:57.203488Z"
    }
   },
   "source": [
    "input_file = \"/Users/audreylaun/Library/CloudStorage/Box-Box/Starling/Experiment1/MEG_data/R3329/R3329.WAV\"\n",
    "output_dir = \"/Users/audreylaun/Library/CloudStorage/Box-Box/Starling/Experiment1/MEG_data/R3329/Recordings\"\n",
    "word_list = \"B2\""
   ],
   "outputs": [],
   "execution_count": 3
>>>>>>> 99371e3f79805ce2c9605203223f22b6524c6a64
  },
  {
   "cell_type": "markdown",
   "id": "916bbf41-98d7-4ce3-910d-25f9ea203ed0",
   "metadata": {},
   "source": [
    "## Loads word lists \n",
    "\n",
    "Uses the .mat files that set variables in the experimental script "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 69,
   "id": "a365fc6d-9edf-4ba3-ab4f-c484dc412ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "if word_list == \"A1\": \n",
    "    titles = loadmat(r\"/Users/admin/Box Sync/Starling/StimComputer/ListA1.mat\")\n",
=======
   "id": "a365fc6d-9edf-4ba3-ab4f-c484dc412ece",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T14:19:59.849449Z",
     "start_time": "2025-09-29T14:19:59.085499Z"
    }
   },
   "source": [
    "if word_list == \"A1\": \n",
    "    titles = loadmat(r\"/Users/audreylaun/Library/CloudStorage/Box-Box/Starling/Experiment1/StimComputer/ListA1.mat\")\n",
>>>>>>> 99371e3f79805ce2c9605203223f22b6524c6a64
    "    no_practice = [i[0][0] for i in titles['wordList']]\n",
    "    with_practice = no_practice.copy()\n",
    "    # Manually adds practice items because they are hardcoded into the script and not contained in List A\n",
    "    with_practice.insert(0,'wrench')\n",
    "    with_practice.insert(0,'gorilla')\n",
    "    with_practice.insert(0,'lawnmower')\n",
    "    with_practice.insert(0,'bell')\n",
    "elif word_list == \"B1\": \n",
<<<<<<< HEAD
    "    titles = loadmat(r\"/Users/admin/Box Sync/Starling/StimComputer/ListB1.mat\")\n",
=======
    "    titles = loadmat(r\"/Users/audreylaun/Library/CloudStorage/Box-Box/Starling/Experiment1/StimComputer/ListB1.mat\")\n",
>>>>>>> 99371e3f79805ce2c9605203223f22b6524c6a64
    "    no_practice = [i[0][0] for i in titles['wordList']]\n",
    "    with_practice = no_practice.copy()\n",
    "    # Manually adds practice items because they are hardcoded into the script and not contained in List B\n",
    "    with_practice.insert(0,'wrench')\n",
    "    with_practice.insert(0,'gorilla')\n",
    "    with_practice.insert(0,'lawnmower')\n",
    "    with_practice.insert(0,'bell')\n",
    "elif word_list == \"A2\": \n",
<<<<<<< HEAD
    "    titles = loadmat(r\"/Users/admin/Box Sync/Starling/StimComputer/ListA2.mat\")\n",
=======
    "    titles = loadmat(r\"/Users/audreylaun/Library/CloudStorage/Box-Box/Starling/Experiment1/StimComputer/ListA2.mat\")\n",
>>>>>>> 99371e3f79805ce2c9605203223f22b6524c6a64
    "    no_practice = [i[0][0] for i in titles['wordList']]\n",
    "    with_practice = no_practice.copy()\n",
    "    # Manually adds practice items because they are hardcoded into the script and not contained in List A\n",
    "    with_practice.insert(0,'wrench')\n",
    "    with_practice.insert(0,'gorilla')\n",
    "    with_practice.insert(0,'lawnmower')\n",
    "    with_practice.insert(0,'bell')\n",
    "else: \n",
<<<<<<< HEAD
    "    titles = loadmat(r\"/Users/admin/Box Sync/Starling/StimComputer/ListB2.mat\")\n",
=======
    "    titles = loadmat(r\"/Users/audreylaun/Library/CloudStorage/Box-Box/Starling/Experiment1/StimComputer/ListB2.mat\")\n",
>>>>>>> 99371e3f79805ce2c9605203223f22b6524c6a64
    "    no_practice = [i[0][0] for i in titles['wordList']]\n",
    "    with_practice = no_practice.copy()\n",
    "    # Manually adds practice items because they are hardcoded into the script and not contained in List A\n",
    "    with_practice.insert(0,'wrench')\n",
    "    with_practice.insert(0,'gorilla')\n",
    "    with_practice.insert(0,'lawnmower')\n",
    "    with_practice.insert(0,'bell')"
<<<<<<< HEAD
   ]
=======
   ],
   "outputs": [],
   "execution_count": 4
>>>>>>> 99371e3f79805ce2c9605203223f22b6524c6a64
  },
  {
   "cell_type": "markdown",
   "id": "df0cea6b-f407-4734-8940-965ed57e1d2a",
   "metadata": {},
   "source": [
    "## Reads wav file of entire production session and defines arrays for the voice recording and trigger pulses\n",
    "\n",
    "Saves the sample rate and the audio data. On our recording device, the audio data will have five channels. The 1st channel (index 0), contains the actual recording of the voice. The 2nd channel (index 1) contains the trigger pulses. "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 71,
   "id": "0fa841c2-bb31-42bb-ae74-ed943ba8d24b",
   "metadata": {},
=======
   "id": "0fa841c2-bb31-42bb-ae74-ed943ba8d24b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T14:20:17.956162Z",
     "start_time": "2025-09-29T14:20:01.150121Z"
    }
   },
   "source": [
    "sample_rate, audio_data = wavfile.read(input_file)"
   ],
>>>>>>> 99371e3f79805ce2c9605203223f22b6524c6a64
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "/var/folders/86/ltqn358s2x5frbwvj9y9w46c0000gp/T/ipykernel_17878/2072101628.py:1: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
=======
      "/var/folders/2q/28nn_1c501nb61yl89b5fy_m0000gn/T/ipykernel_79277/2135057730.py:1: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
>>>>>>> 99371e3f79805ce2c9605203223f22b6524c6a64
      "  sample_rate, audio_data = wavfile.read(input_file)\n"
     ]
    }
   ],
<<<<<<< HEAD
   "source": [
    "sample_rate, audio_data = wavfile.read(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ab585ea4-4eeb-4de2-a036-84da877d8968",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "ab585ea4-4eeb-4de2-a036-84da877d8968",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T14:20:20.919933Z",
     "start_time": "2025-09-29T14:20:17.959921Z"
    }
   },
>>>>>>> 99371e3f79805ce2c9605203223f22b6524c6a64
   "source": [
    "#Channel that contains the voice recording  \n",
    "index = 0\n",
    "audio_channel_0 = []\n",
    "for i in audio_data: \n",
    "    audio_channel_0.append(i[index])"
<<<<<<< HEAD
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8a7b6e4e-a30d-46f5-85a8-cb6dd24c6918",
   "metadata": {},
   "outputs": [],
=======
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "8a7b6e4e-a30d-46f5-85a8-cb6dd24c6918",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T14:20:24.122915Z",
     "start_time": "2025-09-29T14:20:20.925658Z"
    }
   },
>>>>>>> 99371e3f79805ce2c9605203223f22b6524c6a64
   "source": [
    "#Channel that contains the triggers \n",
    "index = 1 \n",
    "pulse_samples = []\n",
    "for i in audio_data: \n",
    "    pulse_samples.append(i[index])"
<<<<<<< HEAD
   ]
=======
   ],
   "outputs": [],
   "execution_count": 7
>>>>>>> 99371e3f79805ce2c9605203223f22b6524c6a64
  },
  {
   "cell_type": "markdown",
   "id": "373434bb-a1d8-411e-97f4-1c395c20227a",
   "metadata": {},
   "source": [
    "## Detect pulses and splice "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 74,
   "id": "74b0bdaa-ad30-4942-ba07-acd54975e344",
   "metadata": {},
=======
   "id": "74b0bdaa-ad30-4942-ba07-acd54975e344",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T14:20:27.876151Z",
     "start_time": "2025-09-29T14:20:24.128569Z"
    }
   },
   "source": [
    "pulses = detect_pulses(pulse_samples, sample_rate)\n",
    "\n",
    "slice_audio(audio_channel_0, pulses, sample_rate, output_dir)"
   ],
>>>>>>> 99371e3f79805ce2c9605203223f22b6524c6a64
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Saved 150 segments to /Users/admin/Box Sync/Starling/MEG_data/R3289/Recordings\n"
     ]
    }
   ],
   "source": [
    "pulses = detect_pulses(pulse_samples, sample_rate)\n",
    "\n",
    "slice_audio(audio_channel_0, pulses, sample_rate, output_dir)"
   ]
=======
      "Saved 150 segments to /Users/audreylaun/Library/CloudStorage/Box-Box/Starling/Experiment1/MEG_data/R3329/Recordings\n"
     ]
    }
   ],
   "execution_count": 8
>>>>>>> 99371e3f79805ce2c9605203223f22b6524c6a64
  }
 ],
 "metadata": {
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
=======
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
>>>>>>> 99371e3f79805ce2c9605203223f22b6524c6a64
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
